{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "c117d10e-0cdb-4eba-b716-e5bebffcd91f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import MinMaxScaler,StandardScaler  # for normalization\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score,f1_score,precision_score,recall_score,roc_curve,auc\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "import random\n",
    "from sklearn.linear_model import SGDClassifier #imported for comparison\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import plot_confusion_matrix\n",
    "random.seed(12)\n",
    "np.random.seed(123)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "3e2b61e6-7038-4d2b-a56a-8ea1ff2bdd7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#For the given file name and target label name, data is extracted from the file and converted into \n",
    "#features and labels, X and Y, respectively\n",
    "def readingToDF(filename,Target_label):\n",
    "    with open(filename) as f: \n",
    "        all_data = f.readlines()\n",
    "    data=[]\n",
    "    for index in all_data:\n",
    "        data.append(index.split())\n",
    "    features=[]\n",
    "    for feature in data[0]:\n",
    "        features.append(feature)\n",
    "    data.pop(0)\n",
    "    #converting to dataframe\n",
    "    train_data = pd.DataFrame(data = np.array(data), columns=features)\n",
    "    #encoding the data into -1 and 1. -1 represents fire as 'no' and 1 with 'yes'\n",
    "    train_data[Target_label]=train_data[Target_label].map({'yes': 1.0, 'no': -1.0})\n",
    "    #selecting the target label\n",
    "    Y = train_data[Target_label]\n",
    "    # selecting all rows and columns excluding 1 representing the label\n",
    "    X = train_data.iloc[:,1:]\n",
    "    return X,Y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a09671d-ead3-4337-902e-8368f44d3115",
   "metadata": {},
   "source": [
    "As described in the assignment details, test and train data should be split in 1:2 ratio 10 times to introduce randomness and perform better evaluations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "4b0b220e-7d4a-4b46-8eb4-406c387d1349",
   "metadata": {},
   "outputs": [],
   "source": [
    "# element of randomness is added and the data is normalized using the standard scaler\n",
    "def CreateTrainAndTest(randomseed,X,Y):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.33, random_state=randomseed)\n",
    "    scaler = StandardScaler()\n",
    "    # normalize data for better convergence and to prevent overflow\n",
    "    X_train_normalized = scaler.fit_transform(X_train)  \n",
    "    X_test_normalized=scaler.transform(X_test)\n",
    "    X_train = pd.DataFrame(X_train_normalized)\n",
    "    X_test=pd.DataFrame(X_test_normalized)\n",
    "    return X_train, X_test, y_train, y_test\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c322f67-b0b5-461e-a36b-bd9603f9ea17",
   "metadata": {},
   "source": [
    "Algorithm:\n",
    "1. fit: \n",
    "        a.initialize the weights and biases\n",
    "        b.repeat the below steps as many times as the epoch or until the loss function steadies\n",
    "        c.for each data point (X,Y), calculate the derivative of the loss function. This gives the           value of dw and db\n",
    "        d.update the current W and b by a factor of dw and db mutiplied by learning rate.\n",
    "2.  predict:\n",
    "        a.use the value of W to calculate f(x)=Xi*W and take the sign of the value.\n",
    "        b. If the sign is +ve, fire is 'yes' else, 'no'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "e8469522-a131-4631-a525-a2e0dee5b698",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SVM(object):\n",
    "\n",
    "    def __init__(self,featuresize):\n",
    "        \n",
    "        self.biases = 1\n",
    "        self.epochs=1000\n",
    "        self.loss_values=[]\n",
    "        self.lr=0.0001\n",
    "        self.C=2\n",
    "        self.weights=[]\n",
    "        self.precision=[]\n",
    "        self.recall=[]\n",
    "        self.f1=[]\n",
    "        self.accuracy=[]\n",
    "        \n",
    "    def fit(self,X_train, y_train):\n",
    "        # stochastic gradient descent\n",
    "        #initializing weights\n",
    "        weights = np.zeros(X_train.shape[1])\n",
    "        b=1\n",
    "        for epoch in range(self.epochs):\n",
    "            # to introduce an element of randomness\n",
    "           # X, Y = shuffle(X_train, y_train)\n",
    "            X, Y = X_train, y_train\n",
    "\n",
    "            l=0 #to calculate the loss\n",
    "            for ind, x in enumerate(X):\n",
    "                l+=self.calculate_loss(weights,x, Y[ind],b)# loss calculated according to the equation\n",
    "                #so that it can be plotted.\n",
    "                dl,db= self.calculate_cost_gradient(weights,x, Y[ind],b)#The gradient of the weights and the biases are calculated\n",
    "                weights = weights - (self.lr * dl) # update weights\n",
    "                b=b-(self.lr*db)   #update bias\n",
    "            l=l/len(X)\n",
    "            self.loss_values.append(l)\n",
    "        self.weights=weights\n",
    "        return weights\n",
    "        # formula in the report is directly applied ie derivative of the loss function\n",
    "    def calculate_cost_gradient(self,W, x, y,b):\n",
    "        distance = 1 - (y * (np.dot(W.T, x)+b)) \n",
    "        if distance<0:\n",
    "            dw = W\n",
    "            db=0\n",
    "        else:\n",
    "            dw =W - (self.C * y * x)\n",
    "            db=-y\n",
    "        return dw,db\n",
    "    # equation given in report. Just used to plot the loss graph. Not used directly \n",
    "    def calculate_loss(self,W, x, y,b):\n",
    "        hinge=1 - (y * (np.dot(x, W)+b))\n",
    "        if hinge<0:\n",
    "            hinge=0\n",
    "        l=self.C*hinge+(np.dot(W.T,W)/2)\n",
    "        return l\n",
    "    #predication is made by using the calculated weights on the datapoint and taking the sign.\n",
    "    def predict(self,X):\n",
    "        label_predicted = np.array([])\n",
    "        for i in range(X.shape[0]):\n",
    "            yp = np.sign(np.dot(X.to_numpy()[i], self.weights))\n",
    "            label_predicted = np.append(label_predicted, yp)\n",
    "        return label_predicted\n",
    "    # just to plot the variation in loss function \n",
    "    def plot_loss(self):\n",
    "        plt.plot(self.loss_values)\n",
    "        plt.title('Variation in loss values with epoch')\n",
    "        plt.xlabel('Number of epochs')\n",
    "        plt.ylabel('Loss Value')\n",
    "        plt.show()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "6cfd8a9b-5166-47d9-b11c-97aa5eebfc2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# to plot the Roc Curve\n",
    "def plot_roc(tr_false_pos,tr_true_pos, tt_false_pos,tt_true_pos,auc_tr,auc_tt):\n",
    "    fig4 = plt.figure(figsize=(5,5))\n",
    "    plt.plot(tr_false_pos, tr_true_pos, label = 'ROC Curve for Train Data: '.format(auc_tr))\n",
    "    plt.plot(tt_false_pos, tt_true_pos, label = 'ROC Curve for Test Data'.format(auc_tt))\n",
    "    plt.legend()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "764081a6-def0-45a3-a22a-781e99a6de11",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Print relevant data for each iteration\n",
    "def evaluate_metrics(y,y_test,pred_train,pred_test):\n",
    "    accuracy=round(accuracy_score(y_test, pred_test),4)\n",
    "    precision=round(precision_score(y_test, pred_test),4)\n",
    "    recall=round(recall_score(y_test, pred_test),4)\n",
    "    f1=round(f1_score(y_test, pred_test),4)\n",
    "    print(\"Evaluation of the Current Run of the Model\")\n",
    "    print('Accuracy of test data: %.3f' % accuracy_score(y_test, pred_test))\n",
    "    # train data is also evaluated to understand underfitting and overfitting.\n",
    "    #Since the accuracy of training data is high, overfitting is very likely\n",
    "    print('Accuracy of train data: %.3f' % accuracy_score(y, pred_train)) \n",
    "\n",
    "    print('Precision of test data: %.3f' % precision_score(y_test, pred_test))\n",
    "    print('Precision of train data: %.3f' % precision_score(y, pred_train))\n",
    "\n",
    "    print('Recall of test data: %.3f' % recall_score(y_test, pred_test))\n",
    "    print('Recall of train data: %.3f' % recall_score(y, pred_train))\n",
    "\n",
    "    print('f1_score of test data: %.3f' % f1_score(y_test, pred_test))\n",
    "    print('f1_score of train data: %.3f' % f1_score(y, pred_train))\n",
    "    tr_false_pos,tr_true_pos,tr_thres=roc_curve(y, pred_train)\n",
    "    tt_false_pos,tt_true_pos,tt_thres=roc_curve(y_test, pred_test)\n",
    "    auc_tr=auc(tr_false_pos, tr_true_pos)\n",
    "    print('auc of train data: %.3f' % auc_tr)\n",
    "\n",
    "    auc_tt=auc(tt_false_pos, tt_true_pos)\n",
    "    print('auc of test data: %.3f' % auc_tt)\n",
    "\n",
    "    plot_roc(tr_false_pos,tr_true_pos, tt_false_pos,tt_true_pos,auc_tr,auc_tt)\n",
    "    return accuracy,precision,recall,f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "79323d6f-3bb1-4690-8e3d-cc64a9f12ba9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def confusion_matrix_plot_new(cm,cm_count,ModelType):\n",
    "    cm=cm/cm_count            \n",
    "    df_cm = pd.DataFrame(cm, index = [i for i in [\"Truelabel -1\",\"True label 1\"]],\n",
    "                  columns = [i for i in [\"Predicted label -1\",\"Predicted label 1\"]])\n",
    "    plt.figure(figsize = (5,4))\n",
    "    if ModelType==1:\n",
    "        plt.title(\"Confusion Matrix for SkLearn Test Data\")\n",
    "    elif ModelType==0:\n",
    "        plt.title(\"Confusion Matrix MySVM Test Data\")\n",
    "    elif ModelType==2:\n",
    "        plt.title(\"Confusion Matrix MySVM Train Data\")\n",
    "    else:\n",
    "        plt.title(\"Confusion Matrix for SkLearn Train Data\")\n",
    "    sns.heatmap(df_cm, cmap=\"Blues\",annot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "b8cce4d7-499b-45f7-95c0-e2849f027cb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#to find the average value of the 10 confusion matrix \n",
    "def calculate_confusion_matrix(cm,cm_count,y_true,y_pred):\n",
    "    cm_new=confusion_matrix(y_true,y_pred)\n",
    "    cm=cm+cm_new\n",
    "    cm_count=cm_count+1\n",
    "    return cm,cm_count\n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8094eb11-3a09-4106-b85b-64169f356827",
   "metadata": {},
   "source": [
    "SGD classifier with hinge loss function is used to compare my implementation as this is similar to the approach taken for my SVM implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "9e56f8ed-bd1c-4afd-81ae-795c391c9889",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def SKlearnSVM(cm1,cm1_count,cm1_t,cm1_ct_t,i):\n",
    "    SVC=SGDClassifier(eta0=0.0001, learning_rate='constant')\n",
    "    \n",
    "    print(\"SK LEARN Linear SVM CLASSIFIER Test Run \",i,\"------------------------------------\")\n",
    "    SVC.fit(X_train,y_train)\n",
    "    pred_test = SVC.predict(X_test)\n",
    "    pred_train = SVC.predict(X_train)\n",
    "    print('weights of sklearn Classifier = ',SVC.coef_)\n",
    "    #for average Calculation\n",
    "    accuracy,precision,recall,f1=evaluate_metrics(y_train,y_test,pred_train,pred_test)\n",
    "    Accuracy_skLearn.append(accuracy)\n",
    "    Precision_skLearn.append(precision)\n",
    "    Recall_skLearn.append(recall)\n",
    "    f1_skLearn.append(f1)\n",
    "    #for confusion matrix plot\n",
    "    cm1,cm1_count=calculate_confusion_matrix(cm1,cm1_count,y_test,pred_test)\n",
    "    cm1_t,cm1_ct_t=calculate_confusion_matrix(cm1_t,cm1_ct_t,y_train,pred_train)\n",
    "    print(\" ----------------------------------------------------------------------------------- \")\n",
    "    return cm1,cm1_count,cm1_t,cm1_ct_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "b8c07fdc-0ef9-4a6e-9a57-a53857b59bf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def MySVM(cm,cm_count,cm_t,cm_ct_t,n ):\n",
    "    SVMClf=SVM(X_train.shape[1])\n",
    "    print(\"Linear SVM CLASSIFIER Custom Implementation Test run \",n,\"----------------------------------\")\n",
    "    W=SVMClf.fit(X_train.to_numpy(),y_train.to_numpy()) # Calculates the weights and biases to classify with the train data\n",
    "    print(\"weights of My SVM Classifier {} \".format(W))\n",
    "    #predicts train and test data\n",
    "    yp_test=SVMClf.predict(X_test)\n",
    "    yp=SVMClf.predict(X_train) \n",
    "    #prints the results\n",
    "    accuracy,precision,recall,f1=evaluate_metrics(y_train,y_test,yp,yp_test)\n",
    "    #for average Calculation\n",
    "    Accuracy_New_impl.append(accuracy)\n",
    "    Precision_New_impl.append(precision)\n",
    "    Recall_New_impl.append(recall)\n",
    "    f1_New_impl.append(f1)\n",
    "    #Plotting Confusion matrix\n",
    "    cm,cm_count=calculate_confusion_matrix(cm,cm_count,y_test,yp_test)\n",
    "    cm_t,cm_ct_t=calculate_confusion_matrix(cm_t,cm_ct_t,y_train,yp)\n",
    "    #Writing the results of each prediction to a file as required in the assignment\n",
    "    df = pd.DataFrame({'Test: Predicted': yp_test, 'Test: Actual': y_test} )  \n",
    "    filename = 'result_{}.csv'.format(n)\n",
    "    df.to_csv(filename,index=False)\n",
    "    #plotting the loss values stored in the class\n",
    "    SVMClf.plot_loss()\n",
    "    print(\" ----------------------------------------------------------------------------------------\")\n",
    "    return cm,cm_count,cm_t,cm_ct_t\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "f48340b9-32a9-4556-b4b9-c268959fc198",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Printing the result of overall test done over 10 iterations with different split of test and train\n",
    "def calculate_test_results():\n",
    "    Tlen=len(Accuracy_New_impl)\n",
    "    TotalA=TotalP=TotalR=Totalf1=0\n",
    "    TotalSkA=TotalSkP=TotalSkR=TotalSkf1=0\n",
    "\n",
    "    for (accuracy,precision,recall,f1) in zip(Accuracy_New_impl,Precision_New_impl,Recall_New_impl,f1_New_impl):\n",
    "        TotalA+=accuracy\n",
    "        TotalP+=precision\n",
    "        TotalR+=recall\n",
    "        Totalf1+=f1\n",
    "    print('Evaluation of from Scratch Implementation of SVM:') \n",
    "    print('Average Accuracy  %.3f' % (TotalA/Tlen)) \n",
    "    print('Average recall=  %.3f' % (TotalR/Tlen)) \n",
    "    print('Average precision=  %.3f' % (TotalP/Tlen) )\n",
    "    print('Average F1_score=  %.3f' %(Totalf1/Tlen) )\n",
    "\n",
    "    for (accuracy,precision,recall,f1) in zip(Accuracy_skLearn,Precision_skLearn,Recall_skLearn,f1_skLearn):\n",
    "        TotalSkA+=accuracy\n",
    "        TotalSkP+=precision\n",
    "        TotalSkR+=recall\n",
    "        TotalSkf1+=f1\n",
    "    print('Evaluation of from SK LEARN Implementation of SVM:') \n",
    "    print('Average Accuracy  %.3f' % (TotalSkA/Tlen) )\n",
    "    print('Average recall=  %.3f' % (TotalSkR/Tlen) )\n",
    "    print('Average precision=  %.3f' % (TotalSkP/Tlen)) \n",
    "    print('Average F1_score=  %.3f' %( TotalSkf1/Tlen)) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "807320ed-fc7c-402e-870b-a31afcfef39c",
   "metadata": {},
   "source": [
    "Run the below cell only to run the machine learning algorithm. Expected format is txt or CSV files that are tab or space seperated. The features should be listed in the first row and the target variable should be passed along with the name of the file to readingToDF(). Additionaly, only Binary classification problems can be handled using this implementation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cdff89f-4c2e-43c6-b45a-e52c0a9d3f73",
   "metadata": {},
   "outputs": [],
   "source": [
    "Accuracy_New_impl=[]\n",
    "Accuracy_skLearn=[]\n",
    "Precision_New_impl=[]\n",
    "Precision_skLearn=[]\n",
    "Recall_New_impl=[]\n",
    "Recall_skLearn=[]\n",
    "f1_New_impl=[]\n",
    "f1_skLearn=[]\n",
    "cm=cm1=cm_train=cm1_train=np.array([[0, 0],[0 ,0]])#parameters to store the average confusion matrix\n",
    "cm_count=cm1_count=cm_ct_train=cm1_ct_train=0\n",
    "X,Y=readingToDF('wildfires.txt','fire')#Make changes to this function to try a different dataset\n",
    "for i in range(10):\n",
    "    X_train, X_test, y_train, y_test=CreateTrainAndTest(i,X,Y)#Creates a differenttrain test split every time\n",
    "    cm,cm_count,cm_train,cm_ct_train=MySVM(cm,cm_count,cm_train,cm_ct_train,i)#creates an instance of SVM\n",
    "    cm1,cm1_count,cm1_train,cm1_ct_train=SKlearnSVM(cm1,cm1_count,cm_train,cm_ct_train,i)#creates an instance of SK Learn SVM\n",
    "\n",
    "calculate_test_results()#Print the average Data of the 10 iterations for comparison\n",
    "confusion_matrix_plot_new(cm,cm_count,0) # outputs the Test data confusion matrix for custom implementaion\n",
    "confusion_matrix_plot_new(cm1,cm1_count,1) # outputs the Test data confusion matrix for SGD Classifier in SK Learn\n",
    "confusion_matrix_plot_new(cm_train,cm_ct_train,2)# outputs the Train data confusion matrix for custom implementaion\n",
    "confusion_matrix_plot_new(cm1_train,cm1_ct_train,3)# outputs the Train data confusion matrix for SGD Classifier in SK Learn\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6d77544-daa4-4fac-8ae3-dfaf97669aba",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
